{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lRbD3t1aDqdg"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from torch import nn,cuda,backends, optim, save, load, no_grad\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder, CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import pickle \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dq74VaaHJ0MS"
   },
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "#mean=[0.6870, 0.5849, 0.5098]\n",
    "#std=[0.2588, 0.3198, 0.3642]\n",
    "\n",
    "#mean=[0.4914, 0.4822, 0.4465]\n",
    "#std=[0.2023, 0.1994, 0.2010]\n",
    "\n",
    "mean=[0.0178, 0.0574, 0.2181]\n",
    "std=[1.0364, 1.0332, 1.0443]\n",
    "\n",
    "transformations=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomInvert(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Normalize(mean=mean,std=std),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size=50\n",
    "# select classes you want to include in your subset\n",
    "classes = torch.tensor([3, 8])\n",
    "classes_names= [\"cat\",\"ship\"]\n",
    "\n",
    "data_train = CIFAR10(root='./data', train=True, download=True, transform=transformations)\n",
    "indices = (torch.tensor(data_train.targets)[..., None] == classes).any(-1).nonzero(as_tuple=True)[0]\n",
    "data_train = torch.utils.data.Subset(data_train, indices)\n",
    "#classes_names=data_train.classes\n",
    "dataloader_train = torch.utils.data.DataLoader(data_train,batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "data_test = CIFAR10(root='./data', train=False, download=True, transform=transformations)\n",
    "indices = (torch.tensor(data_test.targets)[..., None] == classes).any(-1).nonzero(as_tuple=True)[0]\n",
    "data_test = torch.utils.data.Subset(data_test, indices)\n",
    "dataloader_test = torch.utils.data.DataLoader(data_test, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8OheLDGF5ZW",
    "outputId": "e36a96c1-2cb6-47e8-abbe-699d827f7de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get device for pytorch to run on\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "device=\"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, (3072,))\n"
     ]
    }
   ],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "for x_batch,y_batch in dataloader_train:\n",
    "    for i in range(x_batch.shape[0]):\n",
    "        x_train.append(x_batch[i].detach().numpy().flatten())\n",
    "        y_train.append(y_batch[i].detach().numpy().flatten())\n",
    "    \n",
    "print((len(x_train),x_train[0].shape))\n",
    "y_train=np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=[]\n",
    "y_test=[]\n",
    "for x_batch,y_batch in dataloader_test:\n",
    "    for i in range(x_batch.shape[0]):\n",
    "        x_test.append(x_batch[i].detach().numpy().flatten())\n",
    "        y_test.append(y_batch[i].detach().numpy().flatten())\n",
    "y_test=np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "epoches=8000\n",
    "svms={}\n",
    "Cs=[1,0.1,0.001]\n",
    "dfs=[\"ovr\"]\n",
    "kernels=[\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "gammas=[\"auto\",\"scale\",0.001]\n",
    "class_weights=[None]\n",
    "degrees=[3,5]\n",
    "tols=[0.001]\n",
    "for tol in tols:\n",
    "    for c in Cs:\n",
    "        for df in dfs:\n",
    "            for kernel in kernels:\n",
    "                for class_weight in class_weights:\n",
    "                    if (kernel==\"poly\"):\n",
    "                        for degree in degrees:\n",
    "                            for gamma in gammas:\n",
    "                                svm_name=\"kernel_{0}/c_{1}/cw_{2}/dfs_{3}/tol_{4}/gamma_{5}/degree_{6}\".format(kernel,c,class_weight,df,tol,gamma,degree)\n",
    "                                svms[svm_name]=SVC(kernel=kernel, C=c,decision_function_shape=df,gamma=gamma,degree=degree,tol=tol,class_weight=class_weight, max_iter=epoches)\n",
    "                                Path(\"/home/i/ioakeime/Models/svms/\"+svm_name).mkdir(parents=True, exist_ok=True)\n",
    "                    elif (kernel==\"sigmoid\" or kernel==\"rbf\"):\n",
    "                        for gamma in gammas:\n",
    "                            svm_name=\"kernel_{0}/c_{1}/cw_{2}/dfs_{3}/tol_{4}/gamma_{5}\".format(kernel,c,class_weight,df,tol,gamma)\n",
    "                            svms[svm_name]=SVC(kernel=kernel, C=c,decision_function_shape=df,gamma=gamma,tol=tol,class_weight=class_weight, max_iter=epoches)\n",
    "                            Path(\"/home/i/ioakeime/Models/svms/\"+svm_name).mkdir(parents=True, exist_ok=True)\n",
    "                    else:\n",
    "                        svm_name=\"kernel_{0}/c_{1}/cw_{2}/dfs_{3}/tol_{4}/\".format(kernel,c,class_weight,df,tol)\n",
    "                        svms[svm_name]=SVC(kernel=kernel, C=c,decision_function_shape=df,tol=tol,class_weight=class_weight, max_iter=epoches)\n",
    "                        Path(\"/home/i/ioakeime/Models/svms/\"+svm_name).mkdir(parents=True, exist_ok=True)\n",
    "                        \n",
    "                        \n",
    "print(len(svms))\n",
    "#svms[\"kernellinear_C1_dfsovr_maxiter\"+str(epoches)]= SVC(kernel=\"linear\", C=1.0,decision_function_shape=\"ovr\", max_iter=epoches)\n",
    "#svms[\"kernellinear_C0.1_dfsovr_maxiter\"+str(epoches)]= SVC(kernel=\"linear\", C=0.1,decision_function_shape=\"ovr\", max_iter=epoches)\n",
    "\n",
    "#svms[\"kernelsigmoid_C1_dfsovr_gammascale_maxiter\"+str(epoches)]= SVC(kernel=\"sigmoid\", C=1.0,decision_function_shape=\"ovr\", max_iter=epoches,gamma=\"scale\")\n",
    "#svms[\"kernelsigmoid_C0.1_dfsovr_gammaauto_maxiter\"+str(epoches)]= SVC(kernel=\"sigmoid\", C=0.1,decision_function_shape=\"ovr\", max_iter=epoches, gamma=\"auto\")\n",
    "#svms[\"kernelsigmoid_C0.1_dfsovr_gamma0.5_maxiter\"+str(epoches)]= SVC(kernel=\"sigmoid\", C=0.1,decision_function_shape=\"ovr\", max_iter=epoches, gamma=0.5)\n",
    "#svms[\"kernelsigmoid_C0.1_dfsovr_gammaauto_cwbalanced_maxiter\"+str(epoches)]= SVC(kernel=\"sigmoid\", C=0.1,decision_function_shape=\"ovr\", max_iter=epoches, gamma=\"auto\",class_weight=\"balanced\")\n",
    "\n",
    "#svms[\"kernelrbf_C1_dfsovr_gammascale_maxiter\"+str(epoches)]= SVC(kernel=\"rbf\", C=1.0,decision_function_shape=\"ovr\", max_iter=epoches,gamma=\"scale\")\n",
    "#svms[\"kernelrbf_C0.1_dfsovr_gammaauto_maxiter\"+str(epoches)]= SVC(kernel=\"rbf\", C=0.1,decision_function_shape=\"ovr\", max_iter=epoches, gamma=\"auto\")\n",
    "#svms[\"kernelrbf_C0.1_dfsovr_gamma0.5_maxiter\"+str(epoches)]= SVC(kernel=\"rbf\", C=0.1,decision_function_shape=\"ovr\", max_iter=epoches, gamma=0.5)\n",
    "#svms[\"kernelrbf_C0.1_dfsovr_gammaauto_cwbalanced_maxiter\"+str(epoches)]= SVC(kernel=\"rbf\", C=0.1,decision_function_shape=\"ovr\", max_iter=epoches, gamma=\"auto\",class_weight=\"balanced\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_success(cm):\n",
    "    per_class_accuracies = {}\n",
    "    string=\"Accuracies per class:\\n\"\n",
    "    # Calculate the accuracy for each one of our classes\n",
    "    for idx, cls in enumerate(classes_names):\n",
    "        # True negatives are all the samples that are not our current GT class (not the current row) \n",
    "        # and were not predicted as the current class (not the current column)\n",
    "        true_negatives = np.sum(np.delete(np.delete(cm, idx, axis=0), idx, axis=1))\n",
    "    \n",
    "        # True positives are all the samples of our current GT class that were predicted as such\n",
    "        true_positives = cm[idx, idx]\n",
    "    \n",
    "        # The accuracy for the current class is the ratio between correct predictions to all predictions\n",
    "        per_class_accuracies[cls] = float((true_positives + true_negatives) / np.sum(cm))\n",
    "        string+=\"Class: {0}, Accuracy: {1}\\n\".format(cls,per_class_accuracies[cls])\n",
    "    return per_class_accuracies,string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged kernel_rbf/c_1/cw_None/dfs_ovr/tol_0.001/gamma_scale with 6749 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged kernel_sigmoid/c_1/cw_None/dfs_ovr/tol_0.001/gamma_auto with 5329 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_1/cw_None/dfs_ovr/tol_0.001/gamma_scale with 6932 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_1/cw_None/dfs_ovr/tol_0.001/gamma_0.001 with 3513 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged kernel_poly/c_0.1/cw_None/dfs_ovr/tol_0.001/gamma_scale/degree_3 with 6866 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged kernel_rbf/c_0.1/cw_None/dfs_ovr/tol_0.001/gamma_auto with 4094 iterations\n",
      "\n",
      "Converged kernel_rbf/c_0.1/cw_None/dfs_ovr/tol_0.001/gamma_scale with 3955 iterations\n",
      "\n",
      "Converged kernel_rbf/c_0.1/cw_None/dfs_ovr/tol_0.001/gamma_0.001 with 5175 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_0.1/cw_None/dfs_ovr/tol_0.001/gamma_auto with 5631 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_0.1/cw_None/dfs_ovr/tol_0.001/gamma_scale with 7463 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_0.1/cw_None/dfs_ovr/tol_0.001/gamma_0.001 with 4785 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged kernel_poly/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_auto/degree_3 with 4821 iterations\n",
      "\n",
      "Converged kernel_poly/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_scale/degree_3 with 4972 iterations\n",
      "\n",
      "Converged kernel_poly/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_0.001/degree_3 with 7179 iterations\n",
      "\n",
      "Converged kernel_poly/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_auto/degree_5 with 5854 iterations\n",
      "\n",
      "Converged kernel_poly/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_scale/degree_5 with 5000 iterations\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/i/ioakeime/venvs/deeplearning/lib64/python3.9/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=8000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged kernel_rbf/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_auto with 5000 iterations\n",
      "\n",
      "Converged kernel_rbf/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_scale with 5000 iterations\n",
      "\n",
      "Converged kernel_rbf/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_0.001 with 5000 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_auto with 5060 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_scale with 5038 iterations\n",
      "\n",
      "Converged kernel_sigmoid/c_0.001/cw_None/dfs_ovr/tol_0.001/gamma_0.001 with 5045 iterations\n",
      "\n",
      "Best model: ('kernel_rbf/c_1/cw_None/dfs_ovr/tol_0.001/gamma_auto', np.float64(0.868))\n"
     ]
    }
   ],
   "source": [
    "max_accuracy=(\"\",0)\n",
    "log=open(\"/home/i/ioakeime/Models/svms/log.txt\",\"w\")\n",
    "for key in svms.keys():\n",
    "    model=svms[key]\n",
    "    start_training=time.time()\n",
    "    model.fit(x_train,y_train)\n",
    "    stop_training=time.time()\n",
    "    y_pred=model.predict(x_train)\n",
    "    accuracy_train=np.sum(y_train==y_pred)/len(y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy_test=np.sum(y_test==y_pred)/len(y_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    _,class_success_string=calculate_class_success(cm)\n",
    "    if (accuracy_test>max_accuracy[1]):\n",
    "        max_accuracy=(key,accuracy_test)\n",
    "    pickle.dump(model, open(\"/home/i/ioakeime/Models/svms/\"+key+\"/model.sav\", 'wb'))\n",
    "    file=open(\"/home/i/ioakeime/Models/svms/\"+key+\"/log.txt\", 'w')\n",
    "    print(\"Model: {0}, Train Accuracy: {1}, Test Accuracy: {2}, Time trained:{3} seconds\".format(key,accuracy_train,accuracy_test,stop_training-start_training),file=log)\n",
    "    print(\"Confusion matrix:\",cm,\"\\n\",file=log)\n",
    "    print(class_success_string,\"\\n\",file=log)\n",
    "    print('Iterations needed:', np.sum(model.n_iter_),\"\\n\",file=log)\n",
    "    print(\"Model: {0}, Train Accuracy: {1}, Test Accuracy: {2}, Time trained:{3} seconds\".format(key,accuracy_train,accuracy_test,stop_training-start_training),file=file)\n",
    "    print(\"Confusion matrix:\",cm,file=file)\n",
    "    print(class_success_string,file=file)\n",
    "    print('Iterations needed:', np.sum(model.n_iter_),file=file)\n",
    "    if (np.sum(model.n_iter_)<epoches):\n",
    "        print(\"Converged {0} with {1} iterations\\n\".format(key,np.sum(model.n_iter_)),file=log)\n",
    "        print(\"Converged {0} with {1} iterations\\n\".format(key,np.sum(model.n_iter_)),file=file)\n",
    "        print(\"Converged {0} with {1} iterations\\n\".format(key,np.sum(model.n_iter_)))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "log.close()\n",
    "print(\"Best model:\",max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.0205, 0.0601, 0.2227])\n",
      "Std: tensor([1.0364, 1.0332, 1.0443])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean and std of the dataset for normalization\n",
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "for data, _ in dataloader_train:\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "#file=open(\"/Downloads/mean_std.txt\",\"w\")\n",
    "print(\"Mean: \"+str(mean)+\"\\n\"+\"Std: \"+str(std))\n",
    "#file.write(\"Mean: \"+str(mean)+\"\\n\"+\"Std: \"+str(std))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time:37.93816566467285\n"
     ]
    }
   ],
   "source": [
    "with open('/home/i/ioakeime/Models/svms/kernel_rbf/c_1/cw_None/dfs_ovr/tol_0.001/gamma_auto/model.sav', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    start_time=time.time()\n",
    "    y_pred=model.predict(x_test)\n",
    "    accuracy_test=np.sum(y_test==y_pred)/len(y_test)\n",
    "    stop_time=time.time()\n",
    "    print(\"Test time:{0}\".format(stop_time-start_time))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
